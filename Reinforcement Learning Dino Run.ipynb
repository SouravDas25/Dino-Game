{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "from io import BytesIO\n",
    "\n",
    "import cv2  #opencv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "#keras imports\n",
    "from keras.models import Sequential\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "game_url = \"chrome://dino\"\n",
    "chrome_driver_path = \"E:\\Programming\\dino-game\\chromedriver\"\n",
    "loss_file_path = \"./objects/loss_df.csv\"\n",
    "actions_file_path = \"./objects/actions_df.csv\"\n",
    "q_value_file_path = \"./objects/q_values.csv\"\n",
    "scores_file_path = \"./objects/scores_df.csv\"\n",
    "\n",
    "#scripts\n",
    "#create id for canvas for faster selection from DOM\n",
    "init_script = \"document.getElementsByClassName('runner-canvas')[0].id = 'runner-canvas'\"\n",
    "\n",
    "#get image from canvas\n",
    "getbase64Script = \"canvasRunner = document.getElementById('runner-canvas'); \\\n",
    "return canvasRunner.toDataURL().substring(22)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Game class: Selenium interfacing between the python and browser\n",
    "* __init__():  Launch the broswer window using the attributes in chrome_options\n",
    "* get_crashed() : return true if the agent as crashed on an obstacles. Gets javascript variable from game decribing the state\n",
    "* get_playing(): true if game in progress, false is crashed or paused\n",
    "* restart() : sends a signal to browser-javascript to restart the game\n",
    "* press_up(): sends a single to press up get to the browser\n",
    "* get_score(): gets current game score from javascript variables.\n",
    "* pause(): pause the game\n",
    "* resume(): resume a paused game if not crashed\n",
    "* end(): close the browser and end the game\n",
    "'''\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, custom_config=True):\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"disable-infobars\")\n",
    "        chrome_options.add_argument(\"--mute-audio\")\n",
    "        self._driver = webdriver.Chrome(executable_path=chrome_driver_path, chrome_options=chrome_options)\n",
    "        self._driver.set_window_position(x=-10, y=0)\n",
    "        try:\n",
    "            self._driver.get('chrome://dino')\n",
    "        except:\n",
    "            pass\n",
    "        self._driver.execute_script(\"Runner.config.ACCELERATION=0\")\n",
    "        self._driver.execute_script(init_script)\n",
    "\n",
    "    def get_crashed(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "\n",
    "    def get_playing(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.playing\")\n",
    "\n",
    "    def restart(self):\n",
    "        self._driver.execute_script(\"Runner.instance_.restart()\")\n",
    "\n",
    "    def press_up(self):\n",
    "        self._driver.find_element_by_tag_name(\"body\").send_keys(Keys.ARROW_UP)\n",
    "\n",
    "    def get_score(self):\n",
    "        score_array = self._driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(\n",
    "            score_array)  # the javascript object is of type array with score in the formate[1,0,0] which is 100.\n",
    "        return int(score)\n",
    "\n",
    "    def pause(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.stop()\")\n",
    "\n",
    "    def resume(self):\n",
    "        return self._driver.execute_script(\"return Runner.instance_.play()\")\n",
    "\n",
    "    def end(self):\n",
    "        self._driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoAgent:\n",
    "    def __init__(self, game):  #takes game as input for taking actions\n",
    "        self._game = game;\n",
    "        self.jump()  #to start the game, we need to jump once\n",
    "\n",
    "    def is_running(self):\n",
    "        return self._game.get_playing()\n",
    "\n",
    "    def is_crashed(self):\n",
    "        return self._game.get_crashed()\n",
    "\n",
    "    def jump(self):\n",
    "        self._game.press_up()\n",
    "\n",
    "    def duck(self):\n",
    "        self._game.press_down()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game_sate:\n",
    "    def __init__(self, agent, game):\n",
    "        self._agent = agent\n",
    "        self._game = game\n",
    "        self._display = show_img()  #display the processed image on screen using openCV, implemented using python coroutine\n",
    "        self._display.__next__()  # initiliaze the display coroutine\n",
    "\n",
    "    def get_state(self, actions):\n",
    "        actions_df.loc[len(actions_df)] = actions[1]  # storing actions in a dataframe\n",
    "        score = self._game.get_score()\n",
    "        reward = 0.1\n",
    "        is_over = False  #game over\n",
    "        if actions[1] == 1:\n",
    "            self._agent.jump()\n",
    "        image = grab_screen(self._game._driver)\n",
    "        self._display.send(image)  #display the image on screen\n",
    "        if self._agent.is_crashed():\n",
    "            scores_df.loc[len(loss_df)] = score  # log the score when game is over\n",
    "            self._game.restart()\n",
    "            reward = -1\n",
    "            is_over = True\n",
    "        return image, reward, is_over  #return the Experience tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open('objects/' + name + '.pkl', 'wb') as f:  #dump files into objects folder\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('objects/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def grab_screen(_driver):\n",
    "    image_b64 = _driver.execute_script(getbase64Script)\n",
    "    screen = np.array(Image.open(BytesIO(base64.b64decode(image_b64))))\n",
    "    image = process_img(screen)  #processing image as required\n",
    "    return image\n",
    "\n",
    "\n",
    "def process_img(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  #RGB to Grey Scale\n",
    "    image = image[:300, :500]  #Crop Region of Interest(ROI)\n",
    "    image = cv2.resize(image, (80, 80))\n",
    "    return image\n",
    "\n",
    "\n",
    "def show_img(graphs=False):\n",
    "    \"\"\"\n",
    "    Show images in new window\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        screen = (yield)\n",
    "        window_title = \"logs\" if graphs else \"game_play\"\n",
    "        cv2.namedWindow(window_title, cv2.WINDOW_NORMAL)\n",
    "        imS = cv2.resize(screen, (800, 400))\n",
    "        cv2.imshow(window_title, screen)\n",
    "        if (cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize log structures from file if exists else create new\n",
    "loss_df = pd.read_csv(loss_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns=['loss'])\n",
    "scores_df = pd.read_csv(scores_file_path) if os.path.isfile(loss_file_path) else pd.DataFrame(columns=['scores'])\n",
    "actions_df = pd.read_csv(actions_file_path) if os.path.isfile(actions_file_path) else pd.DataFrame(columns=['actions'])\n",
    "q_values_df = pd.read_csv(actions_file_path) if os.path.isfile(q_value_file_path) else pd.DataFrame(columns=['qvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game parameters\n",
    "ACTIONS = 2  # possible actions: jump, do nothing\n",
    "GAMMA = 0.99  # decay rate of past observations original 0.99\n",
    "OBSERVATION = 100.  # timesteps to observe before training\n",
    "EXPLORE = 100000  # frames over which to anneal epsilon\n",
    "FINAL_EPSILON = 0.0001  # final value of epsilon\n",
    "INITIAL_EPSILON = 0.1  # starting value of epsilon\n",
    "REPLAY_MEMORY = 50000  # number of previous transitions to remember\n",
    "BATCH = 16  # size of minibatch\n",
    "FRAME_PER_ACTION = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "img_rows, img_cols = 80, 80\n",
    "img_channels = 4  #We stack 4 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables saved as checkpoints to filesystem to resume training from the same step\n",
    "def init_cache():\n",
    "    \"\"\"initial variable caching, done only once\"\"\"\n",
    "    save_obj(INITIAL_EPSILON, \"epsilon\")\n",
    "    t = 0\n",
    "    save_obj(t, \"time\")\n",
    "    D = deque()\n",
    "    save_obj(D, \"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Call only once to init file structure\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Call only once to init file structure\n",
    "'''\n",
    "#init_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel():\n",
    "    print(\"Now we build the model\")\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(32, (8, 8), padding='same', strides=(4, 4), input_shape=(img_cols, img_rows, img_channels)))  #80*80*4\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3), strides=(1, 1), padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(ACTIONS))\n",
    "    adam = Adam(lr=LEARNING_RATE)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "    #create model file if not present\n",
    "    if not os.path.isfile(loss_file_path):\n",
    "        model.build((1,80,80,1))\n",
    "        model.save_weights('model.h5')\n",
    "    print(\"We finish building the model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "main training module\n",
    "Parameters:\n",
    "* model => Keras Model to be trained\n",
    "* game_state => Game State module with access to game environment and dino\n",
    "* observe => flag to indicate wherther the model is to be trained(weight updates), else just play\n",
    "'''\n",
    "\n",
    "\n",
    "def trainNetwork(model, game_state, observe=False):\n",
    "    last_time = time.time()\n",
    "    # store the previous observations in replay memory\n",
    "    D = load_obj(\"D\")  #load from file system\n",
    "    # get the first state by doing nothing\n",
    "    do_nothing = np.zeros(ACTIONS)\n",
    "    do_nothing[0] = 1  #0 => do nothing,\n",
    "    #1=> jump\n",
    "\n",
    "    x_t, r_0, terminal = game_state.get_state(do_nothing)  # get next step after performing the action\n",
    "\n",
    "    s_t = np.stack((x_t, x_t, x_t, x_t), axis=2)  # stack 4 images to create placeholder input\n",
    "\n",
    "    s_t = s_t.reshape(1, s_t.shape[0], s_t.shape[1], s_t.shape[2])  #1*20*40*4\n",
    "\n",
    "    initial_state = s_t\n",
    "\n",
    "    if observe:\n",
    "        OBSERVE = 999999999  #We keep observe, never train\n",
    "        epsilon = FINAL_EPSILON\n",
    "        print(\"Now we load weight\")\n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse', optimizer=adam)\n",
    "        print(\"Weight load successfully\")\n",
    "    else:  #We go to training mode\n",
    "        OBSERVE = OBSERVATION\n",
    "        epsilon = load_obj(\"epsilon\")\n",
    "        model.load_weights(\"model.h5\")\n",
    "        adam = Adam(lr=LEARNING_RATE)\n",
    "        model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "    t = load_obj(\"time\")  # resume from the previous time step stored in file system\n",
    "    while (True):  #endless running\n",
    "\n",
    "        loss = 0\n",
    "        Q_sa = 0\n",
    "        action_index = 0\n",
    "        r_t = 0  #reward at 4\n",
    "        a_t = np.zeros([ACTIONS])  # action at t\n",
    "\n",
    "        #choose an action epsilon greedy\n",
    "        if t % FRAME_PER_ACTION == 0:  #parameter to skip frames for actions\n",
    "            if random.random() <= epsilon:  #randomly explore an action\n",
    "                print(\"----------Random Action----------\")\n",
    "                action_index = random.randrange(ACTIONS)\n",
    "                a_t[action_index] = 1\n",
    "            else:  # predict the output\n",
    "                q = model.predict(s_t)  #input a stack of 4 images, get the prediction\n",
    "                max_Q = np.argmax(q)  # chosing index with maximum q value\n",
    "                action_index = max_Q\n",
    "                a_t[action_index] = 1  # o=> do nothing, 1=> jump\n",
    "\n",
    "        #We reduced the epsilon (exploration parameter) gradually\n",
    "        if epsilon > FINAL_EPSILON and t > OBSERVE:\n",
    "            epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / EXPLORE\n",
    "\n",
    "            #run the selected action and observed next state and reward\n",
    "        x_t1, r_t, terminal = game_state.get_state(a_t)\n",
    "        print('fps: {0}'.format(1 / (time.time() - last_time)))  # helpful for measuring frame rate\n",
    "        last_time = time.time()\n",
    "        x_t1 = x_t1.reshape(1, x_t1.shape[0], x_t1.shape[1], 1)  #1x20x40x1\n",
    "        s_t1 = np.append(x_t1, s_t[:, :, :, :3], axis=3)  # append the new image to input stack and remove the first one\n",
    "\n",
    "        # store the transition in D\n",
    "        D.append((s_t, action_index, r_t, s_t1, terminal))\n",
    "        if len(D) > REPLAY_MEMORY:\n",
    "            D.popleft()\n",
    "\n",
    "        #only train if done observing\n",
    "        if t > OBSERVE:\n",
    "\n",
    "            #sample a minibatch to train on\n",
    "            minibatch = random.sample(D, BATCH)\n",
    "            inputs = np.zeros((BATCH, s_t.shape[1], s_t.shape[2], s_t.shape[3]))  #32, 20, 40, 4\n",
    "            targets = np.zeros((inputs.shape[0], ACTIONS))  #32, 2\n",
    "\n",
    "            #Now we do the experience replay\n",
    "            for i in range(0, len(minibatch)):\n",
    "                state_t = minibatch[i][0]  # 4D stack of images\n",
    "                action_t = minibatch[i][1]  #This is action index\n",
    "                reward_t = minibatch[i][2]  #reward at state_t due to action_t\n",
    "                state_t1 = minibatch[i][3]  #next state\n",
    "                terminal = minibatch[i][4]  #wheather the agent died or survided due the action\n",
    "\n",
    "                inputs[i:i + 1] = state_t\n",
    "\n",
    "                targets[i] = model.predict(state_t)  # predicted q values\n",
    "                Q_sa = model.predict(state_t1)  #predict q values for next step\n",
    "\n",
    "                if terminal:\n",
    "                    targets[i, action_t] = reward_t  # if terminated, only equals reward\n",
    "                else:\n",
    "                    targets[i, action_t] = reward_t + GAMMA * np.max(Q_sa)\n",
    "\n",
    "            loss += model.train_on_batch(inputs, targets)\n",
    "            loss_df.loc[len(loss_df)] = loss\n",
    "            q_values_df.loc[len(q_values_df)] = np.max(Q_sa)\n",
    "        s_t = initial_state if terminal else s_t1  #reset game to initial frame if terminate\n",
    "        t = t + 1\n",
    "\n",
    "        # save progress every 1000 iterations\n",
    "        if t % 1000 == 0:\n",
    "            print(\"Now we save model\")\n",
    "            game_state._game.pause()  #pause game while saving to filesystem\n",
    "            model.save_weights(\"model.h5\", overwrite=True)\n",
    "            save_obj(D, \"D\")  #saving episodes\n",
    "            save_obj(t, \"time\")  #caching time steps\n",
    "            save_obj(epsilon, \"epsilon\")  #cache epsilon to avoid repeated randomness in actions\n",
    "            loss_df.to_csv(\"./objects/loss_df.csv\", index=False)\n",
    "            scores_df.to_csv(\"./objects/scores_df.csv\", index=False)\n",
    "            actions_df.to_csv(\"./objects/actions_df.csv\", index=False)\n",
    "            q_values_df.to_csv(q_value_file_path, index=False)\n",
    "            with open(\"model.json\", \"w\") as outfile:\n",
    "                json.dump(model.to_json(), outfile)\n",
    "            clear_output()\n",
    "            game_state._game.resume()\n",
    "        # print info\n",
    "        state = \"\"\n",
    "        if t <= OBSERVE:\n",
    "            state = \"observe\"\n",
    "        elif t > OBSERVE and t <= OBSERVE + EXPLORE:\n",
    "            state = \"explore\"\n",
    "        else:\n",
    "            state = \"train\"\n",
    "\n",
    "        print(\"TIMESTEP\", t, \"/ STATE\", state, \"/ EPSILON\", epsilon, \"/ ACTION\", action_index, \"/ REWARD\", r_t,\n",
    "              \"/ Q_MAX \", np.max(Q_sa), \"/ Loss \", loss)\n",
    "\n",
    "    print(\"Episode finished!\")\n",
    "    print(\"************************\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main function\n",
    "def playGame(observe=False):\n",
    "    game = Game()\n",
    "    dino = DinoAgent(game)\n",
    "    game_state = Game_sate(dino, game)\n",
    "    model = buildmodel()\n",
    "    try:\n",
    "        trainNetwork(model, game_state, observe=observe)\n",
    "    except StopIteration:\n",
    "        game.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 7000 / STATE explore / EPSILON 0.09310789899998947 / ACTION 0 / REWARD -1 / Q_MAX  -0.58873814 / Loss  0.006693670060485601\n",
      "fps: 0.36949952300663774\n",
      "TIMESTEP 7001 / STATE explore / EPSILON 0.09310689999998947 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.55603456 / Loss  0.00845547765493393\n",
      "fps: 0.5627452356281272\n",
      "TIMESTEP 7002 / STATE explore / EPSILON 0.09310590099998947 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.82244855 / Loss  0.013020455837249756\n",
      "fps: 0.571428727130543\n",
      "TIMESTEP 7003 / STATE explore / EPSILON 0.09310490199998947 / ACTION 0 / REWARD -1 / Q_MAX  -0.7104302 / Loss  0.008381884545087814\n",
      "fps: 0.556163023780014\n",
      "TIMESTEP 7004 / STATE explore / EPSILON 0.09310390299998947 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8571637 / Loss  0.005142907612025738\n",
      "fps: 0.5485574142610928\n",
      "TIMESTEP 7005 / STATE explore / EPSILON 0.09310290399998947 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9129097 / Loss  0.008280093781650066\n",
      "fps: 0.5665715154865165\n",
      "TIMESTEP 7006 / STATE explore / EPSILON 0.09310190499998947 / ACTION 1 / REWARD -1 / Q_MAX  -0.78412545 / Loss  0.007629430387169123\n",
      "fps: 0.5659310456120316\n",
      "TIMESTEP 7007 / STATE explore / EPSILON 0.09310090599998946 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.96961254 / Loss  0.027116714045405388\n",
      "fps: 0.5479459070009582\n",
      "TIMESTEP 7008 / STATE explore / EPSILON 0.09309990699998946 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9024079 / Loss  0.00399815896525979\n",
      "fps: 0.5633792676680945\n",
      "TIMESTEP 7009 / STATE explore / EPSILON 0.09309890799998946 / ACTION 1 / REWARD -1 / Q_MAX  -1.0138791 / Loss  0.006491942331194878\n",
      "fps: 0.5503570369476162\n",
      "TIMESTEP 7010 / STATE explore / EPSILON 0.09309790899998946 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.63590187 / Loss  0.005433022975921631\n",
      "fps: 0.5282625816313717\n",
      "TIMESTEP 7011 / STATE explore / EPSILON 0.09309690999998946 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.75821793 / Loss  0.004092005547136068\n",
      "fps: 0.5720737493374709\n",
      "TIMESTEP 7012 / STATE explore / EPSILON 0.09309591099998946 / ACTION 1 / REWARD -1 / Q_MAX  -0.7411809 / Loss  0.007796360179781914\n",
      "fps: 0.5717638385719863\n",
      "TIMESTEP 7013 / STATE explore / EPSILON 0.09309491199998945 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0820533 / Loss  0.00752951018512249\n",
      "fps: 0.5714413392720414\n",
      "TIMESTEP 7014 / STATE explore / EPSILON 0.09309391299998945 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.93701345 / Loss  0.013004254549741745\n",
      "fps: 0.5820720373653726\n",
      "TIMESTEP 7015 / STATE explore / EPSILON 0.09309291399998945 / ACTION 0 / REWARD -1 / Q_MAX  -0.90914667 / Loss  0.005558480508625507\n",
      "fps: 0.5512683839741046\n",
      "TIMESTEP 7016 / STATE explore / EPSILON 0.09309191499998945 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.84532994 / Loss  0.007366848178207874\n",
      "fps: 0.5649729751281738\n",
      "TIMESTEP 7017 / STATE explore / EPSILON 0.09309091599998945 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.71561843 / Loss  0.006503176875412464\n",
      "fps: 0.5678403620484852\n",
      "TIMESTEP 7018 / STATE explore / EPSILON 0.09308991699998945 / ACTION 0 / REWARD -1 / Q_MAX  -0.89264613 / Loss  0.009070713073015213\n",
      "fps: 0.5620968095344222\n",
      "TIMESTEP 7019 / STATE explore / EPSILON 0.09308891799998945 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.70932406 / Loss  0.0033413392957299948\n",
      "fps: 0.5583468062121897\n",
      "TIMESTEP 7020 / STATE explore / EPSILON 0.09308791899998944 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.77376795 / Loss  0.010694528929889202\n",
      "fps: 0.5743827955104434\n",
      "TIMESTEP 7021 / STATE explore / EPSILON 0.09308691999998944 / ACTION 0 / REWARD -1 / Q_MAX  -0.837585 / Loss  0.005778032820671797\n",
      "fps: 0.5711028730356316\n",
      "TIMESTEP 7022 / STATE explore / EPSILON 0.09308592099998944 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.88232726 / Loss  0.006515259854495525\n",
      "fps: 0.5494489861016774\n",
      "TIMESTEP 7023 / STATE explore / EPSILON 0.09308492199998944 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.76722425 / Loss  0.0068502770736813545\n",
      "fps: 0.5675373236316833\n",
      "TIMESTEP 7024 / STATE explore / EPSILON 0.09308392299998944 / ACTION 0 / REWARD -1 / Q_MAX  -0.6836899 / Loss  0.006689817178994417\n",
      "----------Random Action----------\n",
      "fps: 0.5364812806673271\n",
      "TIMESTEP 7025 / STATE explore / EPSILON 0.09308292399998944 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8596542 / Loss  0.006665603257715702\n",
      "fps: 0.5659305874511222\n",
      "TIMESTEP 7026 / STATE explore / EPSILON 0.09308192499998943 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.84060735 / Loss  0.003658026224002242\n",
      "fps: 0.5717551091626862\n",
      "TIMESTEP 7027 / STATE explore / EPSILON 0.09308092599998943 / ACTION 1 / REWARD -1 / Q_MAX  -0.61524963 / Loss  0.007886040024459362\n",
      "fps: 0.5543233892317072\n",
      "TIMESTEP 7028 / STATE explore / EPSILON 0.09307992699998943 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6564237 / Loss  0.010067004710435867\n",
      "fps: 0.5574142954576021\n",
      "TIMESTEP 7029 / STATE explore / EPSILON 0.09307892799998943 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6169954 / Loss  0.010438294149935246\n",
      "fps: 0.5678588129659551\n",
      "TIMESTEP 7030 / STATE explore / EPSILON 0.09307792899998943 / ACTION 1 / REWARD -1 / Q_MAX  -0.61939585 / Loss  0.0036389422602951527\n",
      "fps: 0.5617976865899744\n",
      "TIMESTEP 7031 / STATE explore / EPSILON 0.09307692999998943 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8880062 / Loss  0.009467395953834057\n",
      "fps: 0.5580358455499601\n",
      "TIMESTEP 7032 / STATE explore / EPSILON 0.09307593099998943 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.783779 / Loss  0.0066562676802277565\n",
      "fps: 0.5665724338857622\n",
      "TIMESTEP 7033 / STATE explore / EPSILON 0.09307493199998942 / ACTION 1 / REWARD -1 / Q_MAX  -0.86866313 / Loss  0.0035474917385727167\n",
      "fps: 0.5672157378652488\n",
      "TIMESTEP 7034 / STATE explore / EPSILON 0.09307393299998942 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6839724 / Loss  0.008876380510628223\n",
      "fps: 0.5577258985198597\n",
      "TIMESTEP 7035 / STATE explore / EPSILON 0.09307293399998942 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6955005 / Loss  0.004269101656973362\n",
      "fps: 0.5714277150692442\n",
      "TIMESTEP 7036 / STATE explore / EPSILON 0.09307193499998942 / ACTION 0 / REWARD -1 / Q_MAX  -0.89721334 / Loss  0.0068886540830135345\n",
      "fps: 0.5659318855756253\n",
      "TIMESTEP 7037 / STATE explore / EPSILON 0.09307093599998942 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0648012 / Loss  0.002354847267270088\n",
      "fps: 0.526296544976836\n",
      "TIMESTEP 7038 / STATE explore / EPSILON 0.09306993699998942 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.98004705 / Loss  0.005288790445774794\n",
      "fps: 0.5717554209227141\n",
      "TIMESTEP 7039 / STATE explore / EPSILON 0.09306893799998942 / ACTION 0 / REWARD -1 / Q_MAX  -0.8075615 / Loss  0.003858017735183239\n",
      "fps: 0.4962775961932564\n",
      "TIMESTEP 7040 / STATE explore / EPSILON 0.09306793899998941 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7812945 / Loss  0.0046325186267495155\n",
      "fps: 0.55991093335754\n",
      "TIMESTEP 7041 / STATE explore / EPSILON 0.09306693999998941 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.1013194 / Loss  0.003559734672307968\n",
      "fps: 0.5660180332636321\n",
      "TIMESTEP 7042 / STATE explore / EPSILON 0.09306594099998941 / ACTION 1 / REWARD -1 / Q_MAX  -1.1616331 / Loss  0.0022627573926001787\n",
      "fps: 0.5672615358148844\n",
      "TIMESTEP 7043 / STATE explore / EPSILON 0.09306494199998941 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.75333196 / Loss  0.005113853141665459\n",
      "fps: 0.5605715544321771\n",
      "TIMESTEP 7044 / STATE explore / EPSILON 0.09306394299998941 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.96297693 / Loss  0.0047546373680233955\n",
      "fps: 0.5656108957297584\n",
      "TIMESTEP 7045 / STATE explore / EPSILON 0.0930629439999894 / ACTION 1 / REWARD -1 / Q_MAX  -0.96617705 / Loss  0.004391063470393419\n",
      "fps: 0.5649730512300744\n",
      "TIMESTEP 7046 / STATE explore / EPSILON 0.0930619449999894 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0059639 / Loss  0.0056483084335923195\n",
      "fps: 0.5547764323080281\n",
      "TIMESTEP 7047 / STATE explore / EPSILON 0.0930609459999894 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.90427965 / Loss  0.005300374235957861\n",
      "fps: 0.5752479977156327\n",
      "TIMESTEP 7048 / STATE explore / EPSILON 0.0930599469999894 / ACTION 0 / REWARD -1 / Q_MAX  -0.81311256 / Loss  0.005223565734922886\n",
      "fps: 0.5707763029331475\n",
      "TIMESTEP 7049 / STATE explore / EPSILON 0.0930589479999894 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.81386894 / Loss  0.0035097836516797543\n",
      "fps: 0.5592710322469585\n",
      "TIMESTEP 7050 / STATE explore / EPSILON 0.0930579489999894 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6770347 / Loss  0.005906328558921814\n",
      "fps: 0.5714426628006481\n",
      "TIMESTEP 7051 / STATE explore / EPSILON 0.0930569499999894 / ACTION 0 / REWARD -1 / Q_MAX  -0.8122923 / Loss  0.004916512407362461\n",
      "fps: 0.5277046235854037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 7052 / STATE explore / EPSILON 0.0930559509999894 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6408235 / Loss  0.004547004587948322\n",
      "----------Random Action----------\n",
      "fps: 0.5790377570415497\n",
      "TIMESTEP 7053 / STATE explore / EPSILON 0.0930549519999894 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.88320005 / Loss  0.0073694102466106415\n",
      "fps: 0.5659311983324995\n",
      "TIMESTEP 7054 / STATE explore / EPSILON 0.09305395299998939 / ACTION 1 / REWARD -1 / Q_MAX  -0.88146085 / Loss  0.007647787220776081\n",
      "fps: 0.5605376173799506\n",
      "TIMESTEP 7055 / STATE explore / EPSILON 0.09305295399998939 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9174421 / Loss  0.005425114184617996\n",
      "fps: 0.5630625266894981\n",
      "TIMESTEP 7056 / STATE explore / EPSILON 0.09305195499998939 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7864844 / Loss  0.006087565794587135\n",
      "fps: 0.5724116490565718\n",
      "TIMESTEP 7057 / STATE explore / EPSILON 0.09305095599998939 / ACTION 1 / REWARD -1 / Q_MAX  0.73827916 / Loss  0.00546561274677515\n",
      "fps: 0.5714286492795466\n",
      "TIMESTEP 7058 / STATE explore / EPSILON 0.09304995699998939 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.80419016 / Loss  0.006822916679084301\n",
      "fps: 0.5747135855102652\n",
      "TIMESTEP 7059 / STATE explore / EPSILON 0.09304895799998938 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.92343915 / Loss  0.006285273935645819\n",
      "fps: 0.5714276372185235\n",
      "TIMESTEP 7060 / STATE explore / EPSILON 0.09304795899998938 / ACTION 1 / REWARD -1 / Q_MAX  -0.90226686 / Loss  0.00728312274441123\n",
      "fps: 0.5458528019519135\n",
      "TIMESTEP 7061 / STATE explore / EPSILON 0.09304695999998938 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.5674705 / Loss  0.0064207506366074085\n",
      "fps: 0.5104638726332817\n",
      "TIMESTEP 7062 / STATE explore / EPSILON 0.09304596099998938 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.69641376 / Loss  0.0074254535138607025\n",
      "fps: 0.5707759922399688\n",
      "TIMESTEP 7063 / STATE explore / EPSILON 0.09304496199998938 / ACTION 0 / REWARD -1 / Q_MAX  -0.7906327 / Loss  0.004129504784941673\n",
      "fps: 0.5494509294925034\n",
      "TIMESTEP 7064 / STATE explore / EPSILON 0.09304396299998938 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.73936945 / Loss  0.0024960532318800688\n",
      "fps: 0.5630622243373188\n",
      "TIMESTEP 7065 / STATE explore / EPSILON 0.09304296399998938 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.87229997 / Loss  0.005856644827872515\n",
      "fps: 0.5382129826707724\n",
      "TIMESTEP 7066 / STATE explore / EPSILON 0.09304196499998937 / ACTION 0 / REWARD -1 / Q_MAX  -0.98460144 / Loss  0.003969240002334118\n",
      "fps: 0.5552488126029432\n",
      "TIMESTEP 7067 / STATE explore / EPSILON 0.09304096599998937 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.1335584 / Loss  0.007699750363826752\n",
      "fps: 0.5737229059024477\n",
      "TIMESTEP 7068 / STATE explore / EPSILON 0.09303996699998937 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.81686795 / Loss  0.0055368393659591675\n",
      "fps: 0.5817343386594089\n",
      "TIMESTEP 7069 / STATE explore / EPSILON 0.09303896799998937 / ACTION 0 / REWARD -1 / Q_MAX  -0.9216674 / Loss  0.004581356421113014\n",
      "fps: 0.5678589667286383\n",
      "TIMESTEP 7070 / STATE explore / EPSILON 0.09303796899998937 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.96206915 / Loss  0.005862991325557232\n",
      "----------Random Action----------\n",
      "fps: 0.5737236121997026\n",
      "TIMESTEP 7071 / STATE explore / EPSILON 0.09303696999998937 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0504299 / Loss  0.005254712887108326\n",
      "fps: 0.5807213382039871\n",
      "TIMESTEP 7072 / STATE explore / EPSILON 0.09303597099998936 / ACTION 0 / REWARD -1 / Q_MAX  -0.95511496 / Loss  0.008092822507023811\n",
      "fps: 0.5711016288424361\n",
      "TIMESTEP 7073 / STATE explore / EPSILON 0.09303497199998936 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.77043426 / Loss  0.0060284738428890705\n",
      "fps: 0.5730657052685569\n",
      "TIMESTEP 7074 / STATE explore / EPSILON 0.09303397299998936 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.758907 / Loss  0.008466051891446114\n",
      "fps: 0.5767008037614557\n",
      "TIMESTEP 7075 / STATE explore / EPSILON 0.09303297399998936 / ACTION 0 / REWARD -1 / Q_MAX  -0.66716033 / Loss  0.012863583862781525\n",
      "fps: 0.5656110482774859\n",
      "TIMESTEP 7076 / STATE explore / EPSILON 0.09303197499998936 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.70785135 / Loss  0.00929328240454197\n",
      "fps: 0.4818053548657378\n",
      "TIMESTEP 7077 / STATE explore / EPSILON 0.09303097599998936 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.682119 / Loss  0.0072973379865288734\n",
      "fps: 0.32649904275924474\n",
      "TIMESTEP 7078 / STATE explore / EPSILON 0.09302997699998936 / ACTION 0 / REWARD -1 / Q_MAX  -0.94476825 / Loss  0.006248030811548233\n",
      "fps: 0.4612380804605272\n",
      "TIMESTEP 7079 / STATE explore / EPSILON 0.09302897799998935 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9076965 / Loss  0.004921394400298595\n",
      "fps: 0.45127216388362884\n",
      "TIMESTEP 7080 / STATE explore / EPSILON 0.09302797899998935 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8294977 / Loss  0.005926105193793774\n",
      "fps: 0.5479466228410815\n",
      "TIMESTEP 7081 / STATE explore / EPSILON 0.09302697999998935 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.93061197 / Loss  0.008505094796419144\n",
      "fps: 0.508768092921443\n",
      "TIMESTEP 7082 / STATE explore / EPSILON 0.09302598099998935 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7550898 / Loss  0.01090865395963192\n",
      "fps: 0.5117728508196313\n",
      "TIMESTEP 7083 / STATE explore / EPSILON 0.09302498199998935 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.62668467 / Loss  0.00436868891119957\n",
      "fps: 0.4887481868453533\n",
      "TIMESTEP 7084 / STATE explore / EPSILON 0.09302398299998935 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0211188 / Loss  0.009559161961078644\n",
      "fps: 0.41112824075744053\n",
      "TIMESTEP 7085 / STATE explore / EPSILON 0.09302298399998934 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.5966895 / Loss  0.004886162001639605\n",
      "fps: 0.4742497328439817\n",
      "TIMESTEP 7086 / STATE explore / EPSILON 0.09302198499998934 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.5896464 / Loss  0.007280841935425997\n",
      "fps: 0.48744433699649364\n",
      "TIMESTEP 7087 / STATE explore / EPSILON 0.09302098599998934 / ACTION 1 / REWARD -1 / Q_MAX  -0.78664994 / Loss  0.007995794527232647\n",
      "fps: 0.4881411479912481\n",
      "TIMESTEP 7088 / STATE explore / EPSILON 0.09301998699998934 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.77068245 / Loss  0.007026590406894684\n",
      "----------Random Action----------\n",
      "fps: 0.4930050428856265\n",
      "TIMESTEP 7089 / STATE explore / EPSILON 0.09301898799998934 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8442288 / Loss  0.003228918882086873\n",
      "fps: 0.5263505705043425\n",
      "TIMESTEP 7090 / STATE explore / EPSILON 0.09301798899998934 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.70817906 / Loss  0.005522296763956547\n",
      "fps: 0.49188385955657904\n",
      "TIMESTEP 7091 / STATE explore / EPSILON 0.09301698999998934 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.666018 / Loss  0.006067605689167976\n",
      "fps: 0.4892366979312993\n",
      "TIMESTEP 7092 / STATE explore / EPSILON 0.09301599099998933 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.772871 / Loss  0.004271775484085083\n",
      "fps: 0.5293648070110385\n",
      "TIMESTEP 7093 / STATE explore / EPSILON 0.09301499199998933 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9079857 / Loss  0.005287784151732922\n",
      "----------Random Action----------\n",
      "fps: 0.47019748096000774\n",
      "TIMESTEP 7094 / STATE explore / EPSILON 0.09301399299998933 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9229481 / Loss  0.019412478432059288\n",
      "----------Random Action----------\n",
      "fps: 0.5008004584965136\n",
      "TIMESTEP 7095 / STATE explore / EPSILON 0.09301299399998933 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7827935 / Loss  0.005838838871568441\n",
      "fps: 0.5318764812111195\n",
      "TIMESTEP 7096 / STATE explore / EPSILON 0.09301199499998933 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8796184 / Loss  0.004786595702171326\n",
      "fps: 0.5012537606245786\n",
      "TIMESTEP 7097 / STATE explore / EPSILON 0.09301099599998933 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.77419674 / Loss  0.00744231604039669\n",
      "----------Random Action----------\n",
      "fps: 0.505816528775124\n",
      "TIMESTEP 7098 / STATE explore / EPSILON 0.09300999699998933 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9518357 / Loss  0.014207680709660053\n",
      "fps: 0.5302233198423149\n",
      "TIMESTEP 7099 / STATE explore / EPSILON 0.09300899799998932 / ACTION 1 / REWARD -1 / Q_MAX  -0.93731856 / Loss  0.0038425757084041834\n",
      "fps: 0.49925052382391516\n",
      "TIMESTEP 7100 / STATE explore / EPSILON 0.09300799899998932 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.96347517 / Loss  0.002410871908068657\n",
      "fps: 0.5042867276640256\n",
      "TIMESTEP 7101 / STATE explore / EPSILON 0.09300699999998932 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0104283 / Loss  0.0031134544406086206\n",
      "fps: 0.4795819135486478\n",
      "TIMESTEP 7102 / STATE explore / EPSILON 0.09300600099998932 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.069736 / Loss  0.002179989591240883\n",
      "fps: 0.4122183108765658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 7103 / STATE explore / EPSILON 0.09300500199998932 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.73873746 / Loss  0.004151638597249985\n",
      "fps: 0.4313603165959355\n",
      "TIMESTEP 7104 / STATE explore / EPSILON 0.09300400299998932 / ACTION 1 / REWARD -1 / Q_MAX  -0.9794222 / Loss  0.005042682867497206\n",
      "fps: 0.46168211604596715\n",
      "TIMESTEP 7105 / STATE explore / EPSILON 0.09300300399998931 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6505768 / Loss  0.0028785024769604206\n",
      "fps: 0.4446336114618534\n",
      "TIMESTEP 7106 / STATE explore / EPSILON 0.09300200499998931 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8828629 / Loss  0.004501651972532272\n",
      "----------Random Action----------\n",
      "fps: 0.3930821800853172\n",
      "TIMESTEP 7107 / STATE explore / EPSILON 0.09300100599998931 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.610067 / Loss  0.008133905939757824\n",
      "----------Random Action----------\n",
      "fps: 0.36999822953594524\n",
      "TIMESTEP 7108 / STATE explore / EPSILON 0.09300000699998931 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.551256 / Loss  0.004623687360435724\n",
      "fps: 0.45739211606492447\n",
      "TIMESTEP 7109 / STATE explore / EPSILON 0.09299900799998931 / ACTION 0 / REWARD -1 / Q_MAX  -0.69308156 / Loss  0.0047547901049256325\n",
      "fps: 0.4646725453712541\n",
      "TIMESTEP 7110 / STATE explore / EPSILON 0.0929980089999893 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0562785 / Loss  0.008660705760121346\n",
      "fps: 0.40987991115417005\n",
      "TIMESTEP 7111 / STATE explore / EPSILON 0.0929970099999893 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.66875356 / Loss  0.006951811257749796\n",
      "fps: 0.4975103157111124\n",
      "TIMESTEP 7112 / STATE explore / EPSILON 0.0929960109999893 / ACTION 0 / REWARD -1 / Q_MAX  -0.81490064 / Loss  0.003509514732286334\n",
      "fps: 0.4768735913835165\n",
      "TIMESTEP 7113 / STATE explore / EPSILON 0.0929950119999893 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7187224 / Loss  0.005466028116643429\n",
      "fps: 0.4737087008808491\n",
      "TIMESTEP 7114 / STATE explore / EPSILON 0.0929940129999893 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9505882 / Loss  0.003451861906796694\n",
      "fps: 0.5321992077480762\n",
      "TIMESTEP 7115 / STATE explore / EPSILON 0.0929930139999893 / ACTION 0 / REWARD -1 / Q_MAX  -0.6668305 / Loss  0.004747369792312384\n",
      "fps: 0.48262497659829745\n",
      "TIMESTEP 7116 / STATE explore / EPSILON 0.0929920149999893 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7126117 / Loss  0.0035069426521658897\n",
      "fps: 0.48449603762022725\n",
      "TIMESTEP 7117 / STATE explore / EPSILON 0.0929910159999893 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.92643654 / Loss  0.003218957455828786\n",
      "fps: 0.5241058732090599\n",
      "TIMESTEP 7118 / STATE explore / EPSILON 0.0929900169999893 / ACTION 0 / REWARD -1 / Q_MAX  -0.78290135 / Loss  0.006722437683492899\n",
      "fps: 0.4793895164403028\n",
      "TIMESTEP 7119 / STATE explore / EPSILON 0.09298901799998929 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9748601 / Loss  0.0051382738165557384\n",
      "fps: 0.47983906764668466\n",
      "TIMESTEP 7120 / STATE explore / EPSILON 0.09298801899998929 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7208528 / Loss  0.008309002965688705\n",
      "fps: 0.5307936726488203\n",
      "TIMESTEP 7121 / STATE explore / EPSILON 0.09298701999998929 / ACTION 0 / REWARD -1 / Q_MAX  -0.65683824 / Loss  0.004721571691334248\n",
      "fps: 0.4547334494550641\n",
      "TIMESTEP 7122 / STATE explore / EPSILON 0.09298602099998929 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.91386515 / Loss  0.005125023890286684\n",
      "fps: 0.4906757884725284\n",
      "TIMESTEP 7123 / STATE explore / EPSILON 0.09298502199998929 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.68818915 / Loss  0.005089691374450922\n",
      "fps: 0.5408343538252232\n",
      "TIMESTEP 7124 / STATE explore / EPSILON 0.09298402299998929 / ACTION 0 / REWARD -1 / Q_MAX  -0.83407825 / Loss  0.004757448565214872\n",
      "fps: 0.47573701566869325\n",
      "TIMESTEP 7125 / STATE explore / EPSILON 0.09298302399998928 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.68756825 / Loss  0.0037898351438343525\n",
      "fps: 0.47732641924043684\n",
      "TIMESTEP 7126 / STATE explore / EPSILON 0.09298202499998928 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.80779463 / Loss  0.007000318728387356\n",
      "fps: 0.5307863509463422\n",
      "TIMESTEP 7127 / STATE explore / EPSILON 0.09298102599998928 / ACTION 0 / REWARD -1 / Q_MAX  -0.45986137 / Loss  0.005233106669038534\n",
      "fps: 0.4764169138690655\n",
      "TIMESTEP 7128 / STATE explore / EPSILON 0.09298002699998928 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8768088 / Loss  0.004929675720632076\n",
      "fps: 0.48804345296551593\n",
      "TIMESTEP 7129 / STATE explore / EPSILON 0.09297902799998928 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.71942544 / Loss  0.007895896211266518\n",
      "fps: 0.5252096115658953\n",
      "TIMESTEP 7130 / STATE explore / EPSILON 0.09297802899998928 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8672388 / Loss  0.007433675695210695\n",
      "fps: 0.48447645047961885\n",
      "TIMESTEP 7131 / STATE explore / EPSILON 0.09297702999998927 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7780944 / Loss  0.005991628393530846\n",
      "fps: 0.4845859909111474\n",
      "TIMESTEP 7132 / STATE explore / EPSILON 0.09297603099998927 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.72990924 / Loss  0.005430505145341158\n",
      "fps: 0.5309475422860078\n",
      "TIMESTEP 7133 / STATE explore / EPSILON 0.09297503199998927 / ACTION 0 / REWARD -1 / Q_MAX  -0.8475687 / Loss  0.006712672300636768\n",
      "fps: 0.4819300254770147\n",
      "TIMESTEP 7134 / STATE explore / EPSILON 0.09297403299998927 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.56186813 / Loss  0.0076353102922439575\n",
      "fps: 0.4868430170425653\n",
      "TIMESTEP 7135 / STATE explore / EPSILON 0.09297303399998927 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.14653069 / Loss  0.012467036023736\n",
      "fps: 0.4904428457421152\n",
      "TIMESTEP 7136 / STATE explore / EPSILON 0.09297203499998927 / ACTION 0 / REWARD -1 / Q_MAX  -0.6338248 / Loss  0.007377933710813522\n",
      "fps: 0.48343936762322864\n",
      "TIMESTEP 7137 / STATE explore / EPSILON 0.09297103599998927 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6985411 / Loss  0.009384610690176487\n",
      "fps: 0.479956516390746\n",
      "TIMESTEP 7138 / STATE explore / EPSILON 0.09297003699998926 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.83406335 / Loss  0.012852467596530914\n",
      "fps: 0.5273999232471196\n",
      "TIMESTEP 7139 / STATE explore / EPSILON 0.09296903799998926 / ACTION 0 / REWARD -1 / Q_MAX  -0.9299756 / Loss  0.005453668534755707\n",
      "fps: 0.4769774422170179\n",
      "TIMESTEP 7140 / STATE explore / EPSILON 0.09296803899998926 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6449445 / Loss  0.0057662492617964745\n",
      "fps: 0.4789279004267562\n",
      "TIMESTEP 7141 / STATE explore / EPSILON 0.09296703999998926 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.60896575 / Loss  0.005542761646211147\n",
      "fps: 0.534759527375179\n",
      "TIMESTEP 7142 / STATE explore / EPSILON 0.09296604099998926 / ACTION 0 / REWARD -1 / Q_MAX  -0.71027094 / Loss  0.0035366094671189785\n",
      "fps: 0.47471134288866834\n",
      "TIMESTEP 7143 / STATE explore / EPSILON 0.09296504199998926 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8834096 / Loss  0.003953761421144009\n",
      "fps: 0.48685454516119187\n",
      "TIMESTEP 7144 / STATE explore / EPSILON 0.09296404299998925 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0403506 / Loss  0.004535766318440437\n",
      "fps: 0.5310659952979883\n",
      "TIMESTEP 7145 / STATE explore / EPSILON 0.09296304399998925 / ACTION 0 / REWARD -1 / Q_MAX  -0.91166407 / Loss  0.00634145550429821\n",
      "fps: 0.475846094345704\n",
      "TIMESTEP 7146 / STATE explore / EPSILON 0.09296204499998925 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.95834637 / Loss  0.006617581471800804\n",
      "fps: 0.4631778744680163\n",
      "TIMESTEP 7147 / STATE explore / EPSILON 0.09296104599998925 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.95560503 / Loss  0.004893224220722914\n",
      "fps: 0.5154636489280878\n",
      "TIMESTEP 7148 / STATE explore / EPSILON 0.09296004699998925 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.95082283 / Loss  0.003686262760311365\n",
      "fps: 0.4670716629096144\n",
      "TIMESTEP 7149 / STATE explore / EPSILON 0.09295904799998925 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.5151465 / Loss  0.0063572172075510025\n",
      "fps: 0.44385103982612967\n",
      "TIMESTEP 7150 / STATE explore / EPSILON 0.09295804899998925 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6452593 / Loss  0.0043572173453867435\n",
      "fps: 0.49005410651115994\n",
      "TIMESTEP 7151 / STATE explore / EPSILON 0.09295704999998924 / ACTION 1 / REWARD -1 / Q_MAX  -0.8207219 / Loss  0.006332939490675926\n",
      "fps: 0.47921676474435915\n",
      "TIMESTEP 7152 / STATE explore / EPSILON 0.09295605099998924 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7666004 / Loss  0.004845703952014446\n",
      "fps: 0.47732750567112514\n",
      "TIMESTEP 7153 / STATE explore / EPSILON 0.09295505199998924 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.69802094 / Loss  0.006156541872769594\n",
      "fps: 0.5285328454818821\n",
      "TIMESTEP 7154 / STATE explore / EPSILON 0.09295405299998924 / ACTION 0 / REWARD -1 / Q_MAX  -0.5482298 / Loss  0.005798060446977615\n",
      "fps: 0.4868714992686429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 7155 / STATE explore / EPSILON 0.09295305399998924 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.595956 / Loss  0.010195868089795113\n",
      "fps: 0.4854422441407699\n",
      "TIMESTEP 7156 / STATE explore / EPSILON 0.09295205499998924 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.79959255 / Loss  0.006404045037925243\n",
      "fps: 0.5257640167565419\n",
      "TIMESTEP 7157 / STATE explore / EPSILON 0.09295105599998923 / ACTION 0 / REWARD -1 / Q_MAX  -0.64077103 / Loss  0.00441958662122488\n",
      "fps: 0.4836489719398995\n",
      "TIMESTEP 7158 / STATE explore / EPSILON 0.09295005699998923 / ACTION 0 / REWARD 0.1 / Q_MAX  0.8600019 / Loss  0.010211970657110214\n",
      "fps: 0.4709114788759751\n",
      "TIMESTEP 7159 / STATE explore / EPSILON 0.09294905799998923 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8544824 / Loss  0.004758643917739391\n",
      "fps: 0.5305035117697726\n",
      "TIMESTEP 7160 / STATE explore / EPSILON 0.09294805899998923 / ACTION 0 / REWARD -1 / Q_MAX  -0.79342335 / Loss  0.004360673017799854\n",
      "fps: 0.4615673952351518\n",
      "TIMESTEP 7161 / STATE explore / EPSILON 0.09294705999998923 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.99537224 / Loss  0.005022004246711731\n",
      "fps: 0.47505884005246335\n",
      "TIMESTEP 7162 / STATE explore / EPSILON 0.09294606099998923 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.97802866 / Loss  0.004895421210676432\n",
      "----------Random Action----------\n",
      "fps: 0.5428894978946759\n",
      "TIMESTEP 7163 / STATE explore / EPSILON 0.09294506199998923 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.68219984 / Loss  0.0034239906817674637\n",
      "fps: 0.4415002467864343\n",
      "TIMESTEP 7164 / STATE explore / EPSILON 0.09294406299998922 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0213565 / Loss  0.006535923108458519\n",
      "fps: 0.492853843470201\n",
      "TIMESTEP 7165 / STATE explore / EPSILON 0.09294306399998922 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.81338084 / Loss  0.004822138696908951\n",
      "----------Random Action----------\n",
      "fps: 0.5310679453072583\n",
      "TIMESTEP 7166 / STATE explore / EPSILON 0.09294206499998922 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.63692373 / Loss  0.002904564142227173\n",
      "fps: 0.4697040977872314\n",
      "TIMESTEP 7167 / STATE explore / EPSILON 0.09294106599998922 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.85117793 / Loss  0.0023910405579954386\n",
      "fps: 0.49188334038932663\n",
      "TIMESTEP 7168 / STATE explore / EPSILON 0.09294006699998922 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9880205 / Loss  0.004812342580407858\n",
      "----------Random Action----------\n",
      "fps: 0.5307860150932756\n",
      "TIMESTEP 7169 / STATE explore / EPSILON 0.09293906799998922 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0048069 / Loss  0.004224712029099464\n",
      "fps: 0.4700989321771725\n",
      "TIMESTEP 7170 / STATE explore / EPSILON 0.09293806899998922 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7885514 / Loss  0.04347481578588486\n",
      "fps: 0.4693676965262034\n",
      "TIMESTEP 7171 / STATE explore / EPSILON 0.09293706999998921 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.79178977 / Loss  0.002614030847325921\n",
      "fps: 0.5216496914791329\n",
      "TIMESTEP 7172 / STATE explore / EPSILON 0.09293607099998921 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6416896 / Loss  0.004419842269271612\n",
      "fps: 0.48120240023890876\n",
      "TIMESTEP 7173 / STATE explore / EPSILON 0.09293507199998921 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.86960125 / Loss  0.0036344765685498714\n",
      "fps: 0.47281233055686134\n",
      "TIMESTEP 7174 / STATE explore / EPSILON 0.09293407299998921 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.5433172 / Loss  0.0025449898093938828\n",
      "fps: 0.5197509638983899\n",
      "TIMESTEP 7175 / STATE explore / EPSILON 0.09293307399998921 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.60360616 / Loss  0.0034470323007553816\n",
      "----------Random Action----------\n",
      "fps: 0.5030176472761062\n",
      "TIMESTEP 7176 / STATE explore / EPSILON 0.0929320749999892 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8254109 / Loss  0.006584226619452238\n",
      "fps: 0.48449055306121197\n",
      "TIMESTEP 7177 / STATE explore / EPSILON 0.0929310759999892 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.83731544 / Loss  0.007681658025830984\n",
      "----------Random Action----------\n",
      "fps: 0.507473684121375\n",
      "TIMESTEP 7178 / STATE explore / EPSILON 0.0929300769999892 / ACTION 0 / REWARD -1 / Q_MAX  -0.6760837 / Loss  0.00632295710965991\n",
      "fps: 0.4861394803923466\n",
      "TIMESTEP 7179 / STATE explore / EPSILON 0.0929290779999892 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9373853 / Loss  0.004429339896887541\n",
      "fps: 0.4854413451931075\n",
      "TIMESTEP 7180 / STATE explore / EPSILON 0.0929280789999892 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.77774876 / Loss  0.0030088420026004314\n",
      "fps: 0.5339044194509406\n",
      "TIMESTEP 7181 / STATE explore / EPSILON 0.0929270799999892 / ACTION 0 / REWARD -1 / Q_MAX  -0.7886797 / Loss  0.0035700886510312557\n",
      "fps: 0.4803076127819441\n",
      "TIMESTEP 7182 / STATE explore / EPSILON 0.0929260809999892 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9834478 / Loss  0.006341052241623402\n",
      "fps: 0.484496149551296\n",
      "TIMESTEP 7183 / STATE explore / EPSILON 0.0929250819999892 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.94072765 / Loss  0.003666246309876442\n",
      "fps: 0.5319149286944514\n",
      "TIMESTEP 7184 / STATE explore / EPSILON 0.0929240829999892 / ACTION 0 / REWARD -1 / Q_MAX  -0.8173894 / Loss  0.014870320446789265\n",
      "fps: 0.4847188828467138\n",
      "TIMESTEP 7185 / STATE explore / EPSILON 0.09292308399998919 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8921669 / Loss  0.0036355406045913696\n",
      "fps: 0.4746089060231584\n",
      "TIMESTEP 7186 / STATE explore / EPSILON 0.09292208499998919 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.64981246 / Loss  0.004169164225459099\n",
      "fps: 0.5285393725102074\n",
      "TIMESTEP 7187 / STATE explore / EPSILON 0.09292108599998919 / ACTION 0 / REWARD -1 / Q_MAX  -0.75498813 / Loss  0.005729988217353821\n",
      "fps: 0.46511357640650064\n",
      "TIMESTEP 7188 / STATE explore / EPSILON 0.09292008699998919 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0227075 / Loss  0.004351713694632053\n",
      "fps: 0.4880473713735234\n",
      "TIMESTEP 7189 / STATE explore / EPSILON 0.09291908799998919 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.95203626 / Loss  0.004763883538544178\n",
      "fps: 0.5232857116300865\n",
      "TIMESTEP 7190 / STATE explore / EPSILON 0.09291808899998918 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.63689053 / Loss  0.003245668252930045\n",
      "----------Random Action----------\n",
      "fps: 0.4883934046284788\n",
      "TIMESTEP 7191 / STATE explore / EPSILON 0.09291708999998918 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.94430333 / Loss  0.0043827202171087265\n",
      "fps: 0.43440602647551146\n",
      "TIMESTEP 7192 / STATE explore / EPSILON 0.09291609099998918 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.79213494 / Loss  0.003768051275983453\n",
      "fps: 0.5319146588681843\n",
      "TIMESTEP 7193 / STATE explore / EPSILON 0.09291509199998918 / ACTION 0 / REWARD -1 / Q_MAX  -0.7860134 / Loss  0.0031001027673482895\n",
      "fps: 0.48100048188305494\n",
      "TIMESTEP 7194 / STATE explore / EPSILON 0.09291409299998918 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0520461 / Loss  0.005311884451657534\n",
      "fps: 0.4742404025572753\n",
      "TIMESTEP 7195 / STATE explore / EPSILON 0.09291309399998918 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.95274615 / Loss  0.0028851008974015713\n",
      "fps: 0.5193104740203245\n",
      "TIMESTEP 7196 / STATE explore / EPSILON 0.09291209499998918 / ACTION 0 / REWARD -1 / Q_MAX  -0.72991955 / Loss  0.003948284313082695\n",
      "fps: 0.4798466432503833\n",
      "TIMESTEP 7197 / STATE explore / EPSILON 0.09291109599998917 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.59321797 / Loss  0.0027995221316814423\n",
      "fps: 0.47938622894279453\n",
      "TIMESTEP 7198 / STATE explore / EPSILON 0.09291009699998917 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.84250945 / Loss  0.003923352807760239\n",
      "fps: 0.5238343594447209\n",
      "TIMESTEP 7199 / STATE explore / EPSILON 0.09290909799998917 / ACTION 0 / REWARD -1 / Q_MAX  -0.918075 / Loss  0.005214198492467403\n",
      "fps: 0.48685561888630735\n",
      "TIMESTEP 7200 / STATE explore / EPSILON 0.09290809899998917 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.1019193 / Loss  0.004239844623953104\n",
      "fps: 0.47732641924043684\n",
      "TIMESTEP 7201 / STATE explore / EPSILON 0.09290709999998917 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7912798 / Loss  0.003386770375072956\n",
      "fps: 0.523458645208997\n",
      "TIMESTEP 7202 / STATE explore / EPSILON 0.09290610099998917 / ACTION 0 / REWARD -1 / Q_MAX  -0.74998295 / Loss  0.0034900945611298084\n",
      "fps: 0.4885197445392308\n",
      "TIMESTEP 7203 / STATE explore / EPSILON 0.09290510199998916 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.89634615 / Loss  0.0029690100345760584\n",
      "fps: 0.4719209390568521\n",
      "TIMESTEP 7204 / STATE explore / EPSILON 0.09290410299998916 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9478958 / Loss  0.00401314627379179\n",
      "fps: 0.5086471633091394\n",
      "TIMESTEP 7205 / STATE explore / EPSILON 0.09290310399998916 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.73494196 / Loss  0.0054684286005795\n",
      "fps: 0.4391742698131352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 7206 / STATE explore / EPSILON 0.09290210499998916 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.68802613 / Loss  0.002778255380690098\n",
      "----------Random Action----------\n",
      "fps: 0.49236814259187567\n",
      "TIMESTEP 7207 / STATE explore / EPSILON 0.09290110599998916 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0571176 / Loss  0.01169564388692379\n",
      "fps: 0.5249345881789895\n",
      "TIMESTEP 7208 / STATE explore / EPSILON 0.09290010699998916 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.86598176 / Loss  0.008664844557642937\n",
      "fps: 0.48232783012711306\n",
      "TIMESTEP 7209 / STATE explore / EPSILON 0.09289910799998916 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6874941 / Loss  0.005446516443043947\n",
      "fps: 0.4725666973238146\n",
      "TIMESTEP 7210 / STATE explore / EPSILON 0.09289810899998915 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7047212 / Loss  0.0037665702402591705\n",
      "fps: 0.5302220463090233\n",
      "TIMESTEP 7211 / STATE explore / EPSILON 0.09289710999998915 / ACTION 0 / REWARD -1 / Q_MAX  -0.8881607 / Loss  0.0052315853536129\n",
      "fps: 0.4913706501941734\n",
      "TIMESTEP 7212 / STATE explore / EPSILON 0.09289611099998915 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.665138 / Loss  0.004626300185918808\n",
      "fps: 0.48754949971677913\n",
      "TIMESTEP 7213 / STATE explore / EPSILON 0.09289511199998915 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.89673847 / Loss  0.008527519181370735\n",
      "fps: 0.5162617432110163\n",
      "TIMESTEP 7214 / STATE explore / EPSILON 0.09289411299998915 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7056506 / Loss  0.007942980155348778\n",
      "fps: 0.4921264882256653\n",
      "TIMESTEP 7215 / STATE explore / EPSILON 0.09289311399998915 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.96784014 / Loss  0.0034612480085343122\n",
      "fps: 0.47776699190588784\n",
      "TIMESTEP 7216 / STATE explore / EPSILON 0.09289211499998914 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.63067544 / Loss  0.002728273393586278\n",
      "fps: 0.521648718309712\n",
      "TIMESTEP 7217 / STATE explore / EPSILON 0.09289111599998914 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6042399 / Loss  0.002941835904493928\n",
      "fps: 0.4814645563196367\n",
      "TIMESTEP 7218 / STATE explore / EPSILON 0.09289011699998914 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0413796 / Loss  0.0038136658258736134\n",
      "fps: 0.4675083510624009\n",
      "TIMESTEP 7219 / STATE explore / EPSILON 0.09288911799998914 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9169083 / Loss  0.0041665430180728436\n",
      "fps: 0.4825393027041641\n",
      "TIMESTEP 7220 / STATE explore / EPSILON 0.09288811899998914 / ACTION 0 / REWARD -1 / Q_MAX  -0.68176275 / Loss  0.006624947767704725\n",
      "fps: 0.48209011029454446\n",
      "TIMESTEP 7221 / STATE explore / EPSILON 0.09288711999998914 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.83582705 / Loss  0.00362039334140718\n",
      "fps: 0.4887669248335848\n",
      "TIMESTEP 7222 / STATE explore / EPSILON 0.09288612099998914 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0477853 / Loss  0.005685268435627222\n",
      "fps: 0.5202915753731122\n",
      "TIMESTEP 7223 / STATE explore / EPSILON 0.09288512199998913 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0263726 / Loss  0.005313443019986153\n",
      "fps: 0.4670711427859053\n",
      "TIMESTEP 7224 / STATE explore / EPSILON 0.09288412299998913 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0087863 / Loss  0.004075217992067337\n",
      "fps: 0.47824022178521636\n",
      "TIMESTEP 7225 / STATE explore / EPSILON 0.09288312399998913 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.853578 / Loss  0.005428299307823181\n",
      "fps: 0.5256957474998362\n",
      "TIMESTEP 7226 / STATE explore / EPSILON 0.09288212499998913 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.60016865 / Loss  0.007391057908535004\n",
      "fps: 0.47214368427516396\n",
      "TIMESTEP 7227 / STATE explore / EPSILON 0.09288112599998913 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8510038 / Loss  0.0053819469176232815\n",
      "fps: 0.4819283088805573\n",
      "TIMESTEP 7228 / STATE explore / EPSILON 0.09288012699998913 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8665318 / Loss  0.0034603760577738285\n",
      "fps: 0.48685533632660727\n",
      "TIMESTEP 7229 / STATE explore / EPSILON 0.09287912799998913 / ACTION 0 / REWARD -1 / Q_MAX  -0.8822377 / Loss  0.004324312787503004\n",
      "fps: 0.3765061736163705\n",
      "TIMESTEP 7230 / STATE explore / EPSILON 0.09287812899998912 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.85486716 / Loss  0.00692201079800725\n",
      "fps: 0.4657656002954743\n",
      "TIMESTEP 7231 / STATE explore / EPSILON 0.09287712999998912 / ACTION 1 / REWARD -1 / Q_MAX  -0.6400792 / Loss  0.016192499548196793\n",
      "fps: 0.47551151478666737\n",
      "TIMESTEP 7232 / STATE explore / EPSILON 0.09287613099998912 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.74066293 / Loss  0.005868850275874138\n",
      "fps: 0.4710315798505184\n",
      "TIMESTEP 7233 / STATE explore / EPSILON 0.09287513199998912 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6169555 / Loss  0.008504865691065788\n",
      "fps: 0.487425586989167\n",
      "TIMESTEP 7234 / STATE explore / EPSILON 0.09287413299998912 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7429824 / Loss  0.0032946993596851826\n",
      "fps: 0.4734907841371538\n",
      "TIMESTEP 7235 / STATE explore / EPSILON 0.09287313399998912 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9355581 / Loss  0.002077224664390087\n",
      "fps: 0.4703657944820918\n",
      "TIMESTEP 7236 / STATE explore / EPSILON 0.09287213499998911 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.90491605 / Loss  0.008167000487446785\n",
      "fps: 0.5167961992973609\n",
      "TIMESTEP 7237 / STATE explore / EPSILON 0.09287113599998911 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8490384 / Loss  0.0045953975059092045\n",
      "fps: 0.4574580156726365\n",
      "TIMESTEP 7238 / STATE explore / EPSILON 0.09287013699998911 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0108289 / Loss  0.003892898326739669\n",
      "fps: 0.48812484383522875\n",
      "TIMESTEP 7239 / STATE explore / EPSILON 0.09286913799998911 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8193067 / Loss  0.00454908050596714\n",
      "fps: 0.5279931922264491\n",
      "TIMESTEP 7240 / STATE explore / EPSILON 0.09286813899998911 / ACTION 0 / REWARD -1 / Q_MAX  -1.004512 / Loss  0.00963183306157589\n",
      "fps: 0.4833244411462048\n",
      "TIMESTEP 7241 / STATE explore / EPSILON 0.0928671399999891 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0386455 / Loss  0.006167323794215918\n",
      "fps: 0.4782399491373833\n",
      "TIMESTEP 7242 / STATE explore / EPSILON 0.0928661409999891 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8037681 / Loss  0.00408302852883935\n",
      "fps: 0.5221863955776981\n",
      "TIMESTEP 7243 / STATE explore / EPSILON 0.0928651419999891 / ACTION 0 / REWARD -1 / Q_MAX  -0.79319507 / Loss  0.00400463817641139\n",
      "fps: 0.47596327064516947\n",
      "TIMESTEP 7244 / STATE explore / EPSILON 0.0928641429999891 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8924167 / Loss  0.004188088700175285\n",
      "fps: 0.4844965413104439\n",
      "TIMESTEP 7245 / STATE explore / EPSILON 0.0928631439999891 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.81480765 / Loss  0.0028017377480864525\n",
      "fps: 0.5120331896513312\n",
      "TIMESTEP 7246 / STATE explore / EPSILON 0.0928621449999891 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.0280162 / Loss  0.0018966804491356015\n",
      "fps: 0.42644000762534157\n",
      "TIMESTEP 7247 / STATE explore / EPSILON 0.0928611459999891 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.99050397 / Loss  0.00380172417499125\n",
      "fps: 0.4805366405545133\n",
      "TIMESTEP 7248 / STATE explore / EPSILON 0.0928601469999891 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8495993 / Loss  0.0028354357928037643\n",
      "----------Random Action----------\n",
      "fps: 0.5073572353768566\n",
      "TIMESTEP 7249 / STATE explore / EPSILON 0.0928591479999891 / ACTION 1 / REWARD -1 / Q_MAX  -0.82310796 / Loss  0.00591385317966342\n",
      "fps: 0.4844967092074155\n",
      "TIMESTEP 7250 / STATE explore / EPSILON 0.09285814899998909 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8185256 / Loss  0.003747624810785055\n",
      "fps: 0.48449531006954094\n",
      "TIMESTEP 7251 / STATE explore / EPSILON 0.09285714999998909 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.012657 / Loss  0.006657513324171305\n",
      "fps: 0.5262628671919963\n",
      "TIMESTEP 7252 / STATE explore / EPSILON 0.09285615099998909 / ACTION 0 / REWARD -1 / Q_MAX  -0.6710587 / Loss  0.006288920063525438\n",
      "fps: 0.4798479058742558\n",
      "TIMESTEP 7253 / STATE explore / EPSILON 0.09285515199998909 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.64818156 / Loss  0.005716860760003328\n",
      "fps: 0.48899730872777114\n",
      "TIMESTEP 7254 / STATE explore / EPSILON 0.09285415299998909 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7001447 / Loss  0.010066669434309006\n",
      "fps: 0.5307856120701568\n",
      "TIMESTEP 7255 / STATE explore / EPSILON 0.09285315399998909 / ACTION 0 / REWARD -1 / Q_MAX  -0.8151184 / Loss  0.007153170648962259\n",
      "fps: 0.48215971664766255\n",
      "TIMESTEP 7256 / STATE explore / EPSILON 0.09285215499998908 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8886435 / Loss  0.005442979745566845\n",
      "fps: 0.47314237394670283\n",
      "TIMESTEP 7257 / STATE explore / EPSILON 0.09285115599998908 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.60627437 / Loss  0.004052765667438507\n",
      "fps: 0.5219189446702736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 7258 / STATE explore / EPSILON 0.09285015699998908 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.66768473 / Loss  0.0074127307161688805\n",
      "fps: 0.4692645074903463\n",
      "TIMESTEP 7259 / STATE explore / EPSILON 0.09284915799998908 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8203984 / Loss  0.006002385634928942\n",
      "----------Random Action----------\n",
      "fps: 0.4882809425909843\n",
      "TIMESTEP 7260 / STATE explore / EPSILON 0.09284815899998908 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8850875 / Loss  0.005656424909830093\n",
      "fps: 0.4868560144704385\n",
      "TIMESTEP 7261 / STATE explore / EPSILON 0.09284715999998908 / ACTION 0 / REWARD -1 / Q_MAX  -0.57129335 / Loss  0.013570940122008324\n",
      "----------Random Action----------\n",
      "fps: 0.5324812220028045\n",
      "TIMESTEP 7262 / STATE explore / EPSILON 0.09284616099998907 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9715739 / Loss  0.004989129025489092\n",
      "fps: 0.5009957075639374\n",
      "TIMESTEP 7263 / STATE explore / EPSILON 0.09284516199998907 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8536959 / Loss  0.003784062573686242\n",
      "fps: 0.5089064921157365\n",
      "TIMESTEP 7264 / STATE explore / EPSILON 0.09284416299998907 / ACTION 1 / REWARD -1 / Q_MAX  -0.6785166 / Loss  0.005278563126921654\n",
      "fps: 0.4840271090927723\n",
      "TIMESTEP 7265 / STATE explore / EPSILON 0.09284316399998907 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.99242043 / Loss  0.00969625636935234\n",
      "----------Random Action----------\n",
      "fps: 0.496761513129649\n",
      "TIMESTEP 7266 / STATE explore / EPSILON 0.09284216499998907 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7840716 / Loss  0.008335181511938572\n",
      "fps: 0.52274961323196\n",
      "TIMESTEP 7267 / STATE explore / EPSILON 0.09284116599998907 / ACTION 0 / REWARD -1 / Q_MAX  -0.70126027 / Loss  0.004033694043755531\n",
      "fps: 0.47984724711314547\n",
      "TIMESTEP 7268 / STATE explore / EPSILON 0.09284016699998907 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.6308634 / Loss  0.004632206168025732\n",
      "fps: 0.4773259846695463\n",
      "TIMESTEP 7269 / STATE explore / EPSILON 0.09283916799998906 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9760017 / Loss  0.002811603480949998\n",
      "fps: 0.5271467166443624\n",
      "TIMESTEP 7270 / STATE explore / EPSILON 0.09283816899998906 / ACTION 0 / REWARD -1 / Q_MAX  -0.7210174 / Loss  0.005399825982749462\n",
      "fps: 0.47961712083863106\n",
      "TIMESTEP 7271 / STATE explore / EPSILON 0.09283716999998906 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7507274 / Loss  0.0260937362909317\n",
      "fps: 0.4837936267981481\n",
      "TIMESTEP 7272 / STATE explore / EPSILON 0.09283617099998906 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.98485667 / Loss  0.004604020621627569\n",
      "fps: 0.5254861741628631\n",
      "TIMESTEP 7273 / STATE explore / EPSILON 0.09283517199998906 / ACTION 0 / REWARD -1 / Q_MAX  -1.048018 / Loss  0.004088912159204483\n",
      "fps: 0.48426154370328395\n",
      "TIMESTEP 7274 / STATE explore / EPSILON 0.09283417299998906 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.7581461 / Loss  0.006288987118750811\n",
      "fps: 0.45004184098622624\n",
      "TIMESTEP 7275 / STATE explore / EPSILON 0.09283317399998905 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.94248646 / Loss  0.006764812394976616\n",
      "fps: 0.5414213461774537\n",
      "TIMESTEP 7276 / STATE explore / EPSILON 0.09283217499998905 / ACTION 0 / REWARD -1 / Q_MAX  -0.7437407 / Loss  0.008938118815422058\n",
      "fps: 0.48426132005794553\n",
      "TIMESTEP 7277 / STATE explore / EPSILON 0.09283117599998905 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.81905085 / Loss  0.007998127490282059\n",
      "fps: 0.4508579492996783\n",
      "TIMESTEP 7278 / STATE explore / EPSILON 0.09283017699998905 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.75247175 / Loss  0.0074354661628603935\n",
      "fps: 0.5219206981931703\n",
      "TIMESTEP 7279 / STATE explore / EPSILON 0.09282917799998905 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6439419 / Loss  0.008018013089895248\n",
      "fps: 0.4784547829120293\n",
      "TIMESTEP 7280 / STATE explore / EPSILON 0.09282817899998905 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7866428 / Loss  0.0249464213848114\n",
      "fps: 0.47755348205643716\n",
      "TIMESTEP 7281 / STATE explore / EPSILON 0.09282717999998905 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.61218584 / Loss  0.00728388037532568\n",
      "fps: 0.5249309748277922\n",
      "TIMESTEP 7282 / STATE explore / EPSILON 0.09282618099998904 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7009572 / Loss  0.011372732929885387\n",
      "fps: 0.47528881277969637\n",
      "TIMESTEP 7283 / STATE explore / EPSILON 0.09282518199998904 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.48746666 / Loss  0.009390149265527725\n",
      "fps: 0.4803086028212478\n",
      "TIMESTEP 7284 / STATE explore / EPSILON 0.09282418299998904 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.77792656 / Loss  0.0061768414452672005\n",
      "fps: 0.5183115439535012\n",
      "TIMESTEP 7285 / STATE explore / EPSILON 0.09282318399998904 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8118525 / Loss  0.015193651430308819\n",
      "----------Random Action----------\n",
      "fps: 0.4859087410430826\n",
      "TIMESTEP 7286 / STATE explore / EPSILON 0.09282218499998904 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.54619104 / Loss  0.010415637865662575\n",
      "fps: 0.4748339277195291\n",
      "TIMESTEP 7287 / STATE explore / EPSILON 0.09282118599998904 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.4937905 / Loss  0.013029541820287704\n",
      "fps: 0.5263148384428434\n",
      "TIMESTEP 7288 / STATE explore / EPSILON 0.09282018699998903 / ACTION 0 / REWARD -1 / Q_MAX  -0.6790081 / Loss  0.008312629535794258\n",
      "fps: 0.43477986847670147\n",
      "TIMESTEP 7289 / STATE explore / EPSILON 0.09281918799998903 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.5519802 / Loss  0.01437242142856121\n",
      "fps: 0.4840267180924129\n",
      "TIMESTEP 7290 / STATE explore / EPSILON 0.09281818899998903 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.87313634 / Loss  0.00530655775219202\n",
      "fps: 0.5344731883130883\n",
      "TIMESTEP 7291 / STATE explore / EPSILON 0.09281718999998903 / ACTION 0 / REWARD -1 / Q_MAX  -0.7307156 / Loss  0.006481236778199673\n",
      "fps: 0.4907096007616796\n",
      "TIMESTEP 7292 / STATE explore / EPSILON 0.09281619099998903 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.71753126 / Loss  0.009519938379526138\n",
      "fps: 0.45065337854869186\n",
      "TIMESTEP 7293 / STATE explore / EPSILON 0.09281519199998903 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.83707196 / Loss  0.006655438337475061\n",
      "fps: 0.5102043820144216\n",
      "TIMESTEP 7294 / STATE explore / EPSILON 0.09281419299998903 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9700405 / Loss  0.0023592407815158367\n",
      "fps: 0.45724706416660554\n",
      "TIMESTEP 7295 / STATE explore / EPSILON 0.09281319399998902 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.61201483 / Loss  0.008188411593437195\n",
      "fps: 0.4741576257480809\n",
      "TIMESTEP 7296 / STATE explore / EPSILON 0.09281219499998902 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.1412365 / Loss  0.008522211574018002\n",
      "fps: 0.5227493526242197\n",
      "TIMESTEP 7297 / STATE explore / EPSILON 0.09281119599998902 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.1888579 / Loss  0.00665112491697073\n",
      "fps: 0.45454455801454935\n",
      "TIMESTEP 7298 / STATE explore / EPSILON 0.09281019699998902 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9751502 / Loss  0.015602942556142807\n",
      "fps: 0.4750603466397976\n",
      "TIMESTEP 7299 / STATE explore / EPSILON 0.09280919799998902 / ACTION 1 / REWARD 0.1 / Q_MAX  -1.193787 / Loss  0.007823819294571877\n",
      "fps: 0.5192105106140773\n",
      "TIMESTEP 7300 / STATE explore / EPSILON 0.09280819899998902 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.86485344 / Loss  0.0011628956999629736\n",
      "fps: 0.469704518590563\n",
      "TIMESTEP 7301 / STATE explore / EPSILON 0.09280719999998902 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.97115356 / Loss  0.0054020872339606285\n",
      "fps: 0.46698533823532196\n",
      "TIMESTEP 7302 / STATE explore / EPSILON 0.09280620099998901 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.89557916 / Loss  0.004816552624106407\n",
      "fps: 0.48627176006952466\n",
      "TIMESTEP 7303 / STATE explore / EPSILON 0.09280520199998901 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.7411032 / Loss  0.004571234807372093\n",
      "fps: 0.4807289679414612\n",
      "TIMESTEP 7304 / STATE explore / EPSILON 0.09280420299998901 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.6410549 / Loss  0.014552201144397259\n",
      "fps: 0.4885203704286065\n",
      "TIMESTEP 7305 / STATE explore / EPSILON 0.09280320399998901 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9733768 / Loss  0.005016776733100414\n",
      "fps: 0.5274265837432099\n",
      "TIMESTEP 7306 / STATE explore / EPSILON 0.09280220499998901 / ACTION 0 / REWARD -1 / Q_MAX  -0.8922456 / Loss  0.004682312719523907\n",
      "----------Random Action----------\n",
      "fps: 0.49115890227735304\n",
      "TIMESTEP 7307 / STATE explore / EPSILON 0.092801205999989 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8686871 / Loss  0.005483249202370644\n",
      "----------Random Action----------\n",
      "fps: 0.50454114262467\n",
      "TIMESTEP 7308 / STATE explore / EPSILON 0.092800206999989 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9310629 / Loss  0.004273343365639448\n",
      "fps: 0.5273515167989644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP 7309 / STATE explore / EPSILON 0.092799207999989 / ACTION 0 / REWARD -1 / Q_MAX  -0.7842278 / Loss  0.008798952214419842\n",
      "fps: 0.37921924290577336\n",
      "TIMESTEP 7310 / STATE explore / EPSILON 0.092798208999989 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.8391976 / Loss  0.009235993027687073\n",
      "fps: 0.46167479822454105\n",
      "TIMESTEP 7311 / STATE explore / EPSILON 0.092797209999989 / ACTION 0 / REWARD -1 / Q_MAX  -0.73463833 / Loss  0.005782362073659897\n",
      "fps: 0.43552921478964135\n",
      "TIMESTEP 7312 / STATE explore / EPSILON 0.092796210999989 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.54327255 / Loss  0.0067012254148721695\n",
      "fps: 0.41472919572889555\n",
      "TIMESTEP 7313 / STATE explore / EPSILON 0.092795211999989 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9264092 / Loss  0.006566997617483139\n",
      "----------Random Action----------\n",
      "fps: 0.5387376854891361\n",
      "TIMESTEP 7314 / STATE explore / EPSILON 0.092794212999989 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.88326216 / Loss  0.005204196088016033\n",
      "fps: 0.4572473632508127\n",
      "TIMESTEP 7315 / STATE explore / EPSILON 0.092793213999989 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9021763 / Loss  0.0037963674403727055\n",
      "fps: 0.4578744549898585\n",
      "TIMESTEP 7316 / STATE explore / EPSILON 0.09279221499998899 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.9938541 / Loss  0.0026199552230536938\n",
      "fps: 0.4849660438530615\n",
      "TIMESTEP 7317 / STATE explore / EPSILON 0.09279121599998899 / ACTION 0 / REWARD -1 / Q_MAX  -0.73224086 / Loss  0.004712087567895651\n",
      "fps: 0.47972266399487146\n",
      "TIMESTEP 7318 / STATE explore / EPSILON 0.09279021699998899 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9306248 / Loss  0.004678260535001755\n",
      "fps: 0.481087762216266\n",
      "TIMESTEP 7319 / STATE explore / EPSILON 0.09278921799998899 / ACTION 0 / REWARD 0.1 / Q_MAX  -1.0260218 / Loss  0.0044393390417099\n",
      "fps: 0.5120755111349428\n",
      "TIMESTEP 7320 / STATE explore / EPSILON 0.09278821899998899 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8786509 / Loss  0.002164890756830573\n",
      "fps: 0.4739334586442802\n",
      "TIMESTEP 7321 / STATE explore / EPSILON 0.09278721999998898 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9698943 / Loss  0.001547795021906495\n",
      "fps: 0.42443851987137027\n",
      "TIMESTEP 7322 / STATE explore / EPSILON 0.09278622099998898 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.90909266 / Loss  0.006444929633289576\n",
      "fps: 0.4867949890908492\n",
      "TIMESTEP 7323 / STATE explore / EPSILON 0.09278522199998898 / ACTION 0 / REWARD -1 / Q_MAX  -0.7502652 / Loss  0.0033769605215638876\n",
      "fps: 0.3807408476543334\n",
      "TIMESTEP 7324 / STATE explore / EPSILON 0.09278422299998898 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.83544827 / Loss  0.010775978676974773\n",
      "fps: 0.40263720735561215\n",
      "TIMESTEP 7325 / STATE explore / EPSILON 0.09278322399998898 / ACTION 0 / REWARD -1 / Q_MAX  -0.99980545 / Loss  0.004304913803935051\n",
      "fps: 0.42160660682243534\n",
      "TIMESTEP 7326 / STATE explore / EPSILON 0.09278222499998898 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.69888526 / Loss  0.006651772186160088\n",
      "fps: 0.42052102126866026\n",
      "TIMESTEP 7327 / STATE explore / EPSILON 0.09278122599998898 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9411141 / Loss  0.0037834951654076576\n",
      "fps: 0.515196520206609\n",
      "TIMESTEP 7328 / STATE explore / EPSILON 0.09278022699998897 / ACTION 0 / REWARD -1 / Q_MAX  -0.75514877 / Loss  0.006490518804639578\n",
      "fps: 0.48123364953928716\n",
      "TIMESTEP 7329 / STATE explore / EPSILON 0.09277922799998897 / ACTION 0 / REWARD 0.1 / Q_MAX  -0.9230833 / Loss  0.008857391774654388\n",
      "fps: 0.4442359113600704\n",
      "TIMESTEP 7330 / STATE explore / EPSILON 0.09277822899998897 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.92128617 / Loss  0.006155706476420164\n",
      "fps: 0.3884739231003344\n",
      "TIMESTEP 7331 / STATE explore / EPSILON 0.09277722999998897 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.8919023 / Loss  0.0062849633395671844\n",
      "fps: 0.4031918483093413\n",
      "TIMESTEP 7332 / STATE explore / EPSILON 0.09277623099998897 / ACTION 1 / REWARD 0.1 / Q_MAX  -0.91888297 / Loss  0.00762801431119442\n",
      "fps: 0.4258209504966739\n"
     ]
    }
   ],
   "source": [
    "init_cache()\n",
    "playGame(observe=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
